#+TITLE: PLScrape: Scraping Search Results from Public Library Catalogues

* Introduction

Get search information from UK public library service catalogue websites by
web-scraping with BeautifulSoup.

Currently only supports websites based on /prism.librarymanagementcloud.co.uk/. I
plan to also support /capitadiscovery/ and /sirsidynix/.

A public librarian who I know compiled a series of lists of children's books on
different themes as an aid to library users. Every book has been carefully
checked using the online catalogue to make sure that this particular library
authority has copies in stock.

The problem which I am trying to solve is to make these lists more
maintainable. The lists need to be maintained because library stock is in
constant flux - items are withdrawn from stock if they are lost, damaged etc,
and new items are added all the time. Periodically doing manual catalogue checks
on hundreds of items is not at all practical in modern public libraries, where
staffing levels are generally at the bare minimum.

* Usage
** Command Line

This is how you can do a single author and title search at the command line:

#+BEGIN_SRC shell
$ python -i plscrape.py -l islington -a grossmith -t "diary of a nobody"
#+END_SRC

NOTE: Using -i option to enter into interactive python interpreter after running
the script. This way the search-results object can be queried interactively
after the search is done. If you want it to just print the results to the
terminal and then quit, leave out the -i option.

PLScrape Command Line Options:
+ -f = input file
+ -l = library service (e.g. islington)
+ -a = author
+ -t = title
+ -o = output filename
+ -d = discover catalogue

** INTERACTIVE QUERY EXAMPLES:

Use the -i option to interactively query search results in the python REPL (see above).

The list of items found:

: >>> search.items_found

The first item in the list:

: >>> search.items_found[0]

The publisher:

: >>> search.items_found[0].publisher

Number of library branches where book is held:

: >>> len(search.items_found[0].branches)

Name of first library branch in list, and is it currently available:

: >>> search.items_found[0].branches[0].name
: >>> search.items_found[0].branches[0].is_available

** Batch Running
*** How to Run
: $ python plscrape.py -f input_file

*** Writing an Input File

Basic rules:
- Must specify library service before running a search.
- Runs search every time title is given.
- Can abbreviate parameter names to the first letter.
- All text is case-insensitive, but for the sake of readability, I like to write
  parameter names in uppercase and values in lowercase.
- lines beginning with hash (#) are comments

EXAMPLE:
#+BEGIN_SRC config
LIBRARYSERVICE=islington

AUTHOR=grossmith
TITLE=diary of a nobody

AUTHOR=bukowski
TITLE=factotum
#+END_SRC

EXAMPLE: parameter names abbreviated to first character
#+BEGIN_SRC config
L=islington

A=grossmith
T=diary of a nobody

A=bukowski
T=factotum
#+END_SRC
* Dependencies
- Python 3
- requests
- argparse
- BeautifulSoup (bs4)

* Copyright and License

Project website: https://github.com/bstancham/capita-library-search

Copyright 2019-present, B. S. Tancham (formerly B. S. Chambers)

Released under the GPL, version 3
